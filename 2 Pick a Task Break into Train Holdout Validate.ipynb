{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0 Loading Data\n",
    "- Outcome: Load whole dataset as `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is loaded...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('../Data/train_data_ads.csv')\n",
    "print(\"data is loaded...\") # 31.8 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 Pick a Advertisement Task\n",
    "\n",
    "- Outcome: \n",
    "    - Load Task 18800 as `df_18800`\n",
    "    - Drop the Columns with unique value > 1000 or non-numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18800 = df[df['task_id'] == 18800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                 int64\n",
      "age                   int64\n",
      "gender                int64\n",
      "residence             int64\n",
      "city                  int64\n",
      "city_rank             int64\n",
      "series_dev            int64\n",
      "series_group          int64\n",
      "emui_dev              int64\n",
      "device_name           int64\n",
      "device_size           int64\n",
      "net_type              int64\n",
      "task_id               int64\n",
      "adv_id                int64\n",
      "creat_type_cd         int64\n",
      "adv_prim_id           int64\n",
      "inter_type_cd         int64\n",
      "slot_id               int64\n",
      "site_id               int64\n",
      "spread_app_id         int64\n",
      "hispace_app_tags      int64\n",
      "app_second_class      int64\n",
      "app_score           float64\n",
      "u_refreshTimes        int64\n",
      "u_feedLifeCycle       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Importing the NumPy library, which provides support for large, multi-dimensional arrays and matrices,\n",
    "# along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\n",
    "columns_to_drop = [column for column in df_18800.columns if df_18800[column].nunique() > 1000]\n",
    "# Constructing a list of columns from the dataframe 'df_18800' to be dropped.\n",
    "# A column is added to this list if it has more than 1000 unique values, which typically\n",
    "# suggests that the column contains highly granular data, possibly not useful for analysis\n",
    "# or could lead to issues like overfitting if used in machine learning models.\n",
    "\n",
    "df_18800 = df_18800.drop(columns=columns_to_drop)\n",
    "# Removing the columns identified in the 'columns_to_drop' list from 'df_18800'.\n",
    "# This operation simplifies the dataframe by excluding columns with excessive uniqueness.\n",
    "\n",
    "df_18800 = df_18800.select_dtypes(include=[np.number])\n",
    "# Filtering the dataframe to include only columns that have numerical data types.\n",
    "# This step is crucial for analyses that require numerical inputs, such as mathematical\n",
    "# operations or statistical modeling.\n",
    "\n",
    "print(df_18800.dtypes)\n",
    "# Printing the data types of the columns remaining in the dataframe 'df_18800'.\n",
    "# This is useful for verifying that the dataframe now contains only numerical columns,\n",
    "# as intended after the previous filtering step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 Break Dataset into Training, Holdout, Validate\n",
    "- Outcome: `df_18800_train`, `df_18800_holdout`, `df_18800_val`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 Check Positive Sample Size, Negative Sample Size, Label Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample size is 398, Negative Sample size is 13020, label rate is 0.03\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each label in the 'label' column of df_18800 dataframe.\n",
    "label_counts = df_18800['label'].value_counts()\n",
    "# Extract the count of positive labels (label == 1) from the label_counts series.\n",
    "positive_count = label_counts[1]\n",
    "# Extract the count of negative labels (label == 0) from the label_counts series.\n",
    "negative_count = label_counts[0]\n",
    "# Calculate the rate of positive labels to negative labels.\n",
    "label_rate = positive_count / negative_count\n",
    "# Print the sizes of positive and negative samples along with the label rate, formatted to two decimal places.\n",
    "print(\"Positive Sample size is {}, Negative Sample size is {}, label rate is {:.2f}\".format(positive_count, negative_count, label_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_0 = df_18800[df_18800['label'] == 0]\n",
    "df_label_1 = df_18800[df_18800['label'] == 1]\n",
    "\n",
    "# 對 label 為 0 的數據集進行分割\n",
    "total_samples_label_0 = len(df_label_0)\n",
    "train_size_label_0 = int(0.4 * total_samples_label_0)\n",
    "holdout_size_label_0 = int(0.4 * total_samples_label_0)\n",
    "validate_size_label_0 = total_samples_label_0 - train_size_label_0 - holdout_size_label_0\n",
    "\n",
    "df_label_0_train = df_label_0.sample(n=train_size_label_0, random_state=42)\n",
    "df_label_0_hold = df_label_0.drop(df_label_0_train.index).sample(n=holdout_size_label_0, random_state=42)\n",
    "df_label_0_val = df_label_0.drop(df_label_0_train.index).drop(df_label_0_hold.index)\n",
    "\n",
    "# 對 label 為 1 的數據集進行分割\n",
    "total_samples_label_1 = len(df_label_1)\n",
    "train_size_label_1 = int(0.4 * total_samples_label_1)\n",
    "holdout_size_label_1 = int(0.4 * total_samples_label_1)\n",
    "validate_size_label_1 = total_samples_label_1 - train_size_label_1 - holdout_size_label_1\n",
    "\n",
    "df_label_1_train = df_label_1.sample(n=train_size_label_1, random_state=42)\n",
    "df_label_1_hold = df_label_1.drop(df_label_1_train.index).sample(n=holdout_size_label_1, random_state=42)\n",
    "df_label_1_val = df_label_1.drop(df_label_1_train.index).drop(df_label_1_hold.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 label 為 0 和 label 為 1 的 train 子數據集合併成 df_train\n",
    "df_train = pd.concat([df_label_0_train, df_label_1_train])\n",
    "\n",
    "# 將 label 為 0 和 label 為 1 的 holdout 子數據集合併成 df_holdout\n",
    "df_holdout = pd.concat([df_label_0_hold, df_label_1_hold])\n",
    "\n",
    "# 將 label 為 0 和 label 為 1 的 validate 子數據集合併成 df_val\n",
    "df_val = pd.concat([df_label_0_val, df_label_1_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calculate_label_rate(df):\n",
    "    \n",
    "    # Get the total number of samples\n",
    "    total_samples = len(df)\n",
    "    \n",
    "    # Count the occurrences of each label in the 'label' column of df dataframe.\n",
    "    label_counts = df['label'].value_counts()\n",
    "    # Extract the count of positive labels (label == 1) from the label_counts series.\n",
    "    positive_count = label_counts.get(1, 0)\n",
    "    # Extract the count of negative labels (label == 0) from the label_counts series.\n",
    "    negative_count = label_counts.get(0, 0)\n",
    "    # Calculate the rate of positive labels to negative labels.\n",
    "    label_rate = positive_count / negative_count if negative_count != 0 else 0\n",
    "    \n",
    "    # Print the sizes of positive and negative samples along with the label rate, formatted to two decimal places.\n",
    "    print(\"Total Sample size is {}, Positive Sample size is {}, Negative Sample size is {}, label rate is {:.2f}\".format(total_samples, positive_count, negative_count, label_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sample size is 13418, Positive Sample size is 398, Negative Sample size is 13020, label rate is 0.03\n",
      "Total Sample size is 5367, Positive Sample size is 159, Negative Sample size is 5208, label rate is 0.03\n",
      "Total Sample size is 5367, Positive Sample size is 159, Negative Sample size is 5208, label rate is 0.03\n",
      "Total Sample size is 2684, Positive Sample size is 80, Negative Sample size is 2604, label rate is 0.03\n"
     ]
    }
   ],
   "source": [
    "calculate_label_rate(df_18800)\n",
    "calculate_label_rate(df_train)\n",
    "calculate_label_rate(df_holdout)\n",
    "calculate_label_rate(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 Save the three sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sample size is 5367, Positive Sample size is 159, Negative Sample size is 5208, label rate is 0.03\n",
      "Total Sample size is 5367, Positive Sample size is 159, Negative Sample size is 5208, label rate is 0.03\n",
      "Total Sample size is 2684, Positive Sample size is 80, Negative Sample size is 2604, label rate is 0.03\n"
     ]
    }
   ],
   "source": [
    "# 將df_train的行隨機重新排序\n",
    "df_train_shuffled = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 將df_holdout的行隨機重新排序\n",
    "df_holdout_shuffled = df_holdout.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# 將df_val的行隨機重新排序\n",
    "df_val_shuffled = df_val.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "calculate_label_rate(df_train_shuffled)\n",
    "calculate_label_rate(df_holdout_shuffled)\n",
    "calculate_label_rate(df_val_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存隨機排序後的df_train\n",
    "df_train_shuffled.to_csv('../Data/df_18800_train.csv', index=False)\n",
    "\n",
    "# 儲存隨機排序後的df_holdout\n",
    "df_holdout_shuffled.to_csv('../Data/df_18800_holdout.csv', index=False)\n",
    "\n",
    "# 儲存隨機排序後的df_val\n",
    "df_val_shuffled.to_csv('../Data/df_18800_val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
